{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af524363",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/unionai-oss/bert-llm-classification-pipeline\n",
    "    %cd bert-llm-classification-pipeline\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24988b74",
   "metadata": {},
   "source": [
    "### üîê Authenticate\n",
    "To use **Union.ai**, you'll need to authenticate your account. Follow the appropriate step based on your setup:  \n",
    "\n",
    "##### üî∏ **Using Union BYOC Enterprise**  \n",
    "\n",
    "If you're using a **[Union BYOC Enterprise](https://www.union.ai/pricing)** account, log in with the following command:  \n",
    "```bash\n",
    "union create login --host <union-host-url>\n",
    "```\n",
    "\n",
    "Replace <union-host-url> with your organization's Union instance URL.\n",
    "\n",
    "##### üî∏ Using Union Serverless\n",
    "If you're using [Union Serverless](https://www.union.ai/) , authenticate by running the command below:\n",
    "\n",
    "Create an account for free at [Union.ai](https://union.ai) if you don't have one yet:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b121e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåü Authenticate to union serverless\n",
    "!union create login --serverless --auth device-flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb871b",
   "metadata": {},
   "source": [
    "## Training Faster RCNN Object Detetection Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a93053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!union run --remote workflows/train-frcnn-pipeline.py faster_rcnn_train_workflow --epochs 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef371fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile workflow.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c102c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# containers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd18f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirmets.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8900e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f0c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f7e7ef0",
   "metadata": {},
   "source": [
    "## Run Model Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a1aa63",
   "metadata": {},
   "source": [
    " lets pull donw our same datset locally to run the model on examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d440fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hub download data\n",
    "\n",
    "def download_hf_dataset(repo_id: str = 'sagecodes/union_swag_coco',\n",
    "                        local_dir: str = \"dataset\",\n",
    "                        sub_folder: str = \"swag\"):\n",
    "    \n",
    "    from huggingface_hub import snapshot_download\n",
    "\n",
    "    if local_dir:\n",
    "        dataset_dir = os.path.join(local_dir)\n",
    "        os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Download the dataset repository\n",
    "    repo_path = snapshot_download(repo_id=repo_id, \n",
    "                                  repo_type=\"dataset\",\n",
    "                                  local_dir=local_dir)\n",
    "    if sub_folder:\n",
    "        repo_path = os.path.join(repo_path, sub_folder)\n",
    "        # use sub_folder to return a specific folder from the dataset\n",
    "\n",
    "    print(f\"Dataset downloaded to {repo_path}\")\n",
    "\n",
    "    print(f\"Files in dataset directory: {os.listdir(repo_path)}\")\n",
    "\n",
    "    return repo_path\n",
    "\n",
    "download_hf_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc90613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84040cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw boxes on images\n",
    "\n",
    "# Define labels map\n",
    "labels_map = {1: \"Union Sticker\", 2: \"Flyte Sticker\"}\n",
    "\n",
    "# Check and set the available device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "font_url = 'https://github.com/google/fonts/raw/main/apache/robotomono/RobotoMono%5Bwght%5D.ttf'\n",
    "response = requests.get(font_url)\n",
    "font = ImageFont.truetype(BytesIO(response.content), size=20)\n",
    "\n",
    "\n",
    "# Function to draw bounding boxes\n",
    "def draw_boxes(image, boxes, labels, scores, labels_map):\n",
    "    draw = ImageDraw.Draw(image, 'RGBA')\n",
    "    # font = ImageFont.truetype(urlopen(truetype_url), size=20)\n",
    "    # font = ImageFont.load_default() # default font in pil\n",
    "\n",
    "\n",
    "    colors = {\n",
    "        0: (255, 173, 10, 200),  # Class 0 color (e.g., blue)\n",
    "        1: (28, 140, 252, 200),  # Class 1 color (e.g., orange)\n",
    "    }\n",
    "    colors_fill = {\n",
    "        0: (255, 173, 10, 100),  # Class 0 fill color (e.g., bluea)\n",
    "        1: (28, 140, 252, 100),  # Class 1 fill color (e.g., orangea)\n",
    "    }\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score > 0.6: # adjust threshold as needed\n",
    "          color = colors.get(label, (0, 255, 0, 200))\n",
    "          fill_color = colors_fill.get(label, (0, 255, 0, 100))\n",
    "          draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline=color, width=3)\n",
    "          draw.rectangle([(box[0], box[1]), (box[2], box[3])], fill=fill_color)\n",
    "          label_text = f\"{labels_map[label]}: {score:.2f}\"\n",
    "          text_size = font.getbbox(label_text)\n",
    "          draw.rectangle([(box[0], box[1] - text_size[1]), (box[0] + text_size[0], box[1])], fill=color)\n",
    "          draw.text((box[0], box[1] - text_size[1]), label_text, fill=\"white\", font=font)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "# Load a single test image\n",
    "image_path = '/content/dataset/swag/images/1bd5a6b5-20240916_133544.jpg'\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image_tensor = F.to_tensor(image).unsqueeze(0).to(device)\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(image_tensor)\n",
    "\n",
    "# Get the boxes, labels, and scores\n",
    "boxes = outputs[0]['boxes'].cpu().numpy()\n",
    "labels = outputs[0]['labels'].cpu().numpy()\n",
    "scores = outputs[0]['scores'].cpu().numpy()\n",
    "\n",
    "# Define labels map\n",
    "labels_map = {0: \"Background\", 1: \"Union Sticker\", 2: \"Flyte Sticker\"}\n",
    "\n",
    "# Draw the boxes on the image\n",
    "image_with_boxes = draw_boxes(image, boxes, labels, scores, labels_map)\n",
    "\n",
    "# Display the image\n",
    "image_with_boxes.show()\n",
    "\n",
    "# Save the image\n",
    "image_with_boxes.save('output_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c90f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference on video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webcam example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a72e519",
   "metadata": {},
   "source": [
    "## Serving as an App on Union\n",
    "\n",
    "We can serve our model as an app on Union. This allows us to run the model in a production environment and make it available for use by other applications or users.\n",
    "\n",
    "This example will use Gradio, but we could also use any other web framework like Flask or FastAPI to serve our model as an API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdf5e5e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
